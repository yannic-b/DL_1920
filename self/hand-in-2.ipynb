{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# This code does not need to be modified!\n",
    "\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Lambda(lambda x: x.squeeze()),\n",
    "                                ])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data_mnist',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=transform\n",
    "                                      )\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data_mnist',\n",
    "                                     train=False,\n",
    "                                     download=True,\n",
    "                                     transform=transform\n",
    "                                     )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This code does not need to be modified!\n",
    "\n",
    "bs=128\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=bs,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True\n",
    "                                          )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=bs,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True\n",
    "                                         )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "GPU is available!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  print('GPU is available!')\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  print('GPU is not available!')\n",
    "  device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# This code does not need to be modified!\n",
    "\n",
    "class TwoLayerNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size1, output_size):\n",
    "        super(TwoLayerNet , self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1, bias=False)\n",
    "        self.layer2 = nn.Linear(hidden_size1, output_size, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y       = self.layer1(x)\n",
    "        y_hat   = F.relu(y)\n",
    "        z       = self.layer2(y_hat)\n",
    "        return F.softmax(z, dim=1)\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net=TwoLayerNet(784, 64, 10).to(device)  # Move the model to GPU\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(net.parameters() , lr=0.1)\n",
    "# optimizer=torch.optim.Adam(net.parameters())\n",
    "\n",
    "results = []\n",
    "\n",
    "for epoch in range(0, 17):\n",
    "    print(\"Starting epoch: \", epoch)\n",
    "    if epoch > 0:\n",
    "        for i, (minibatch_data, minibatch_label) in enumerate(trainloader):\n",
    "              minibatch_data, minibatch_label = minibatch_data.to(device), minibatch_label.to(device)  # Move the data to GPU\n",
    "        \n",
    "              # Set dL/dU, dL/dV, dL/dW to be filled with zeros\n",
    "              optimizer.zero_grad()\n",
    "              \n",
    "              #reshape the minibatch\n",
    "              inputs = minibatch_data.view(bs, 784)\n",
    "        \n",
    "              # forward the minibatch through the net  \n",
    "              prob=net(inputs) \n",
    "              \n",
    "              # Compute the average of the losses of the data points in the minibatch\n",
    "              loss = criterion(prob , minibatch_label) \n",
    "              \n",
    "              # backward pass to compute dL/dU, dL/dV and dL/dW    \n",
    "              loss.backward()\n",
    "              \n",
    "              # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "              optimizer.step()\n",
    "      \n",
    "    # Evaluate the model on the test set\n",
    "    print(\"Finished training, starting evaluation...\")\n",
    "    correct_total = 0\n",
    "    for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "        \n",
    "            y_pred = net(x_batch.view(bs, 784))\n",
    "            y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "            correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "    accuracy = correct_total / len(testset.data)\n",
    "    print(accuracy)\n",
    "    results.append((epoch, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class SLayerNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, layers, output_size):\n",
    "        super(SLayerNet , self).__init__()\n",
    "        self.nr_l = layers\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.layerS = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y       = self.layer1(x)\n",
    "        y_hat   = F.relu(y)\n",
    "        h_hat = y_hat\n",
    "        for s in range(self.nr_l):\n",
    "            h = self.layerS(h_hat)\n",
    "            h_hat = F.relu(h)\n",
    "        z = self.layer2(h_hat)\n",
    "        return F.softmax(z, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting epoch:  0\n",
      "Starting epoch:  1\n",
      "Starting epoch:  2\n",
      "Starting epoch:  3\n",
      "Starting epoch:  4\n",
      "Starting epoch:  5\n",
      "Starting epoch:  6\n",
      "Starting epoch:  7\n",
      "Starting epoch:  8\n",
      "Starting epoch:  9\n",
      "Starting epoch:  10\n",
      "Starting epoch:  11\n",
      "Starting epoch:  12\n",
      "Starting epoch:  13\n",
      "Starting epoch:  14\n",
      "Starting epoch:  15\n",
      "Starting epoch:  16\n",
      "Finished training, starting evaluation...\n",
      "0.9688\n",
      "Starting epoch:  0\n",
      "Starting epoch:  1\n",
      "Starting epoch:  2\n",
      "Starting epoch:  3\n",
      "Starting epoch:  4\n",
      "Starting epoch:  5\n",
      "Starting epoch:  6\n",
      "Starting epoch:  7\n",
      "Starting epoch:  8\n",
      "Starting epoch:  9\n",
      "Starting epoch:  10\n",
      "Starting epoch:  11\n",
      "Starting epoch:  12\n",
      "Starting epoch:  13\n",
      "Starting epoch:  14\n",
      "Starting epoch:  15\n",
      "Starting epoch:  16\n",
      "Finished training, starting evaluation...\n",
      "0.9642\n",
      "Starting epoch:  0\n",
      "Starting epoch:  1\n",
      "Starting epoch:  2\n",
      "Starting epoch:  3\n",
      "Starting epoch:  4\n",
      "Starting epoch:  5\n",
      "Starting epoch:  6\n",
      "Starting epoch:  7\n",
      "Starting epoch:  8\n",
      "Starting epoch:  9\n",
      "Starting epoch:  10\n",
      "Starting epoch:  11\n",
      "Starting epoch:  12\n",
      "Starting epoch:  13\n",
      "Starting epoch:  14\n",
      "Starting epoch:  15\n",
      "Starting epoch:  16\n",
      "Finished training, starting evaluation...\n",
      "0.9605\n",
      "Starting epoch:  0\n",
      "Starting epoch:  1\n",
      "Starting epoch:  2\n",
      "Starting epoch:  3\n",
      "Starting epoch:  4\n",
      "Starting epoch:  5\n",
      "Starting epoch:  6\n",
      "Starting epoch:  7\n",
      "Starting epoch:  8\n",
      "Starting epoch:  9\n",
      "Starting epoch:  10\n",
      "Starting epoch:  11\n",
      "Starting epoch:  12\n",
      "Starting epoch:  13\n",
      "Starting epoch:  14\n",
      "Starting epoch:  15\n",
      "Starting epoch:  16\n",
      "Finished training, starting evaluation...\n",
      "0.9655\n",
      "Starting epoch:  0\n",
      "Starting epoch:  1\n",
      "Starting epoch:  2\n",
      "Starting epoch:  3\n",
      "Starting epoch:  4\n",
      "Starting epoch:  5\n",
      "Starting epoch:  6\n",
      "Starting epoch:  7\n",
      "Starting epoch:  8\n",
      "Starting epoch:  9\n",
      "Starting epoch:  10\n",
      "Starting epoch:  11\n",
      "Starting epoch:  12\n",
      "Starting epoch:  13\n",
      "Starting epoch:  14\n",
      "Starting epoch:  15\n",
      "Starting epoch:  16\n",
      "Finished training, starting evaluation...\n",
      "0.9529\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "results = []\n",
    "for l in range(1,6):\n",
    "    net=SLayerNet(784, 64, l, 10).to(device)  # Move the model to GPU\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer=torch.optim.SGD(net.parameters() , lr=0.1)\n",
    "    optimizer=torch.optim.Adam(net.parameters())\n",
    "    \n",
    "    for epoch in range(0, 17):\n",
    "        print(\"Starting epoch: \", epoch)\n",
    "        for i, (minibatch_data, minibatch_label) in enumerate(trainloader):\n",
    "              minibatch_data, minibatch_label = minibatch_data.to(device), minibatch_label.to(device)  # Move the data to GPU\n",
    "        \n",
    "              # Set dL/dU, dL/dV, dL/dW to be filled with zeros\n",
    "              optimizer.zero_grad()\n",
    "              \n",
    "              #reshape the minibatch\n",
    "              inputs = minibatch_data.view(bs, 784)\n",
    "        \n",
    "              # forward the minibatch through the net  \n",
    "              prob=net(inputs) \n",
    "              \n",
    "              # Compute the average of the losses of the data points in the minibatch\n",
    "              loss = criterion(prob , minibatch_label) \n",
    "              \n",
    "              # backward pass to compute dL/dU, dL/dV and dL/dW    \n",
    "              loss.backward()\n",
    "              \n",
    "              # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "              optimizer.step()\n",
    "      \n",
    "    # Evaluate the model on the test set\n",
    "    print(\"Finished training, starting evaluation...\")\n",
    "    correct_total = 0\n",
    "    for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "        \n",
    "            y_pred = net(x_batch.view(bs, 784))\n",
    "            y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "            correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "    accuracy = correct_total / len(testset.data)\n",
    "    print(accuracy)\n",
    "    results.append((l, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code does not need to be modified!\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(*zip(*results))\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "if type(net) is SLayerNet:\n",
    "    plt.xlabel(\"Number of hidden layers\")\n",
    "    plt.xticks(np.arange(1, 6, step=1))\n",
    "else:\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.xticks(np.arange(1, 17, step=1))\n",
    "opti_name = optimizer.__class__.__name__\n",
    "plt.text(5, 0.9, opti_name, horizontalalignment='center', verticalalignment='center')\n",
    "# plt.savefig('./figs/%s_acc-vs-epochs.png' % opti_name)\n",
    "plt.savefig('./figs/%s_acc-vs-layers.png' % opti_name)\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-76f97117",
   "language": "python",
   "display_name": "PyCharm (DL_1920)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}